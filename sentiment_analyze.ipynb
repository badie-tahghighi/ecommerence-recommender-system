{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302482,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('assets/csv/reviews_dataset.csv')\n",
    "bad_words = pd.read_csv('assets/csv/bad_words.csv')\n",
    "amazon_reviews = pd.read_json('assets/json/Clothing_Shoes_and_Jewelry_5.json', lines=True)\n",
    "amazon_reviews.dropna(inplace=True)\n",
    "data = data.dropna()\n",
    "bad_words = bad_words.dropna()\n",
    "bad_words_rate = pd.DataFrame(np.zeros((bad_words.shape[0], 1)).astype(int))\n",
    "\n",
    "amazon_texts = amazon_reviews['reviewText']\n",
    "\n",
    "x = data['text']\n",
    "x = pd.concat([x, bad_words['jigaboo'], amazon_texts], ignore_index=True)\n",
    "\n",
    "y = data['rate']\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "accuracy = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "amazon_rates = amazon_reviews['overall'].astype(int)\n",
    "amazon_rates = amazon_rates.apply(lambda rate: 1 if rate > accuracy else 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "x = x.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "\n",
    "def contractions(s):\n",
    "    s = re.sub(r\"won’t\", \"will not \", s)\n",
    "    s = re.sub(r\"would’t\", \"would not \", s)\n",
    "    s = re.sub(r\"could’t\", \"could not \", s)\n",
    "    s = re.sub(r\"\\’d\", \" would\", s)\n",
    "    s = re.sub(r\"can\\’t\", \"can not \", s)\n",
    "    s = re.sub(r\"n\\’t\", \" not \", s)\n",
    "    s = re.sub(r\"\\’re\", \" are\", s)\n",
    "    s = re.sub(r\"\\’s\", \" is \", s)\n",
    "    s = re.sub(r\"\\’ll\", \" will\", s)\n",
    "    s = re.sub(r\"\\’t\", \" not \", s)\n",
    "    s = re.sub(r\"\\’ve\", \" have\", s)\n",
    "    s = re.sub(r\"\\’m\", \" am\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "x = x.apply(lambda text: contractions(text))\n",
    "\n",
    "x = x.apply(lambda x: \" \".join([re.sub('[^A-Za-z]+', '', x) for x in nltk.word_tokenize(x)]))\n",
    "x = x.apply(lambda text: re.sub(' +', ' ', text))\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "x = x.apply(lambda text: \" \".join([text for text in text.split() if text not in stop]))\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "x = x.apply(lambda text: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302482, 1)\n"
     ]
    }
   ],
   "source": [
    "y = y.apply(lambda rate: 1 if rate > accuracy else 0)\n",
    "\n",
    "y = pd.concat([y, bad_words_rate, amazon_rates])\n",
    "y.reset_index(inplace=True)\n",
    "y.drop(columns=['index'], inplace=True)\n",
    "\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "processed_x = vectorizer.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_x, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gustav\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, solver='saga')\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.7827674082237068, 'recall': 0.7126062012101452, 'f1-score': 0.7460408632149012, 'support': 31897}, '1': {'precision': 0.8032114719962218, 'recall': 0.8557314060927637, 'f1-score': 0.8286400832715072, 'support': 43724}, 'accuracy': 0.7953610769495246, 'macro avg': {'precision': 0.7929894401099643, 'recall': 0.7841688036514545, 'f1-score': 0.7873404732432041, 'support': 75621}, 'weighted avg': {'precision': 0.7945881490812655, 'recall': 0.7953610769495246, 'f1-score': 0.7937996643118854, 'support': 75621}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rate 1/0:\t 0\n"
     ]
    }
   ],
   "source": [
    "sample_review = pd.DataFrame([\"The delivery was so late and my package was damaged i contacted their support and they didn't respond complete trash doesn't recommend.\"])\n",
    "\n",
    "sample_review = sample_review.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "sample_review = sample_review.apply(lambda text: contractions(text))\n",
    "sample_review = sample_review.apply(lambda x: \" \".join([re.sub('[^A-Za-z]+', '', x) for x in nltk.word_tokenize(x)]))\n",
    "sample_review = sample_review.apply(lambda text: re.sub(' +', ' ', text))\n",
    "sample_review = sample_review.apply(lambda text: \" \".join([text for text in text.split() if text not in stop]))\n",
    "sample_review = sample_review.apply(lambda text: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text)]))\n",
    "\n",
    "vectorizer_2 = TfidfVectorizer(vocabulary=vectorizer.get_feature_names_out())\n",
    "\n",
    "processed_text = vectorizer_2.fit_transform(sample_review)\n",
    "\n",
    "y_test_pred = clf.predict(processed_text)\n",
    "print('Predicted rate 1/0:\\t', y_test_pred[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   review  rate\n",
      "0             absolutely wonderful silky sexy comfortable     0\n",
      "1       love dress sooo pretty happened find store gla...     1\n",
      "2       high hope dress really wanted work initially o...     0\n",
      "3       love love love jumpsuit fun flirty fabulous ev...     1\n",
      "4       shirt flattering due adjustable front tie perf...     1\n",
      "...                                                   ...   ...\n",
      "302477  nt normally go gaga product often cube awesome...     1\n",
      "302478  traveling back forth england since three packe...     1\n",
      "302479  nice packing cube x laundry storage bag nice b...     1\n",
      "302480  vacation family four shacke pak set wonderful ...     1\n",
      "302481  signed receive free set shacke pak review thou...     1\n",
      "\n",
      "[302482 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['review'] = x\n",
    "output['rate'] = y\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "output.to_csv('assets/csv/output.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}